{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, csc_matrix, find, coo_matrix\n",
    "from scipy.sparse import eye, spdiags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.linalg import eigh\n",
    "from scipy.io import  savemat\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat kernel graphs\n",
    "\n",
    "\n",
    "def heat_kernel_on_graph(signal, laplacian, time, steps):\n",
    "    h = time / steps\n",
    "    n_vertices = laplacian.shape[0]\n",
    "\n",
    "    # solve Ax=b\n",
    "    time_step = lambda x: spsolve(eye(n_vertices) - h * laplacian, x)\n",
    "\n",
    "    result = signal.copy()\n",
    "    for i in range(steps):\n",
    "        result = time_step(result)\n",
    "\n",
    "        # help fix numerical issues\n",
    "        result[result < 0] = 0\n",
    "        result = result / np.sum(result) * np.sum(signal)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MESH heat kernel and conv wasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cot(x):\n",
    "    return np.cos(x)/np.sin(x)\n",
    "\n",
    "\n",
    "def cot_laplacian(X, T):\n",
    "    nv = X.shape[0]\n",
    "    nf = T.shape[0]\n",
    "\n",
    "    # Find original edge lengths and angles\n",
    "    L1 = np.linalg.norm(X[T[:, 1], :] - X[T[:, 2], :], axis=1)\n",
    "    L2 = np.linalg.norm(X[T[:, 0], :] - X[T[:, 2], :], axis=1)\n",
    "    L3 = np.linalg.norm(X[T[:, 0], :] - X[T[:, 1], :], axis=1)\n",
    "    EL = np.column_stack((L1, L2, L3))\n",
    "    A1 = (L2**2 + L3**2 - L1**2) / (2 * L2 * L3)\n",
    "    A2 = (L1**2 + L3**2 - L2**2) / (2 * L1 * L3)\n",
    "    A3 = (L1**2 + L2**2 - L3**2) / (2 * L1 * L2)\n",
    "    A = np.column_stack((A1, A2, A3))\n",
    "    A = np.arccos(A)\n",
    "\n",
    "    # The Cot Laplacian\n",
    "    I = [T[:, 0], T[:, 1], T[:, 2]]\n",
    "    J = [T[:, 1], T[:, 2], T[:, 0]]\n",
    "    S = 0.5 * 1 / np.tan([A[:, 2], A[:, 0], A[:, 1]]).flatten()\n",
    "    \n",
    "    In = np.vstack((I, J, I, J)).flatten()\n",
    "    Jn = np.vstack((J, I, I, J)).flatten()\n",
    "    Sn = np.vstack((-S, -S, S, S)).flatten()\n",
    "\n",
    "    # Compute the areas. Use mixed weights Voronoi areas\n",
    "    cA = 0.5 * 1 / np.tan(A)\n",
    "    vp1 = [1, 2, 0]\n",
    "    vp2 = [2, 0, 1]\n",
    "    At = 1 / 4 * (EL[:, vp1] ** 2 * cA[:, vp1] + EL[:, vp2] ** 2 * cA[:, vp2])\n",
    "\n",
    "    # Triangle areas\n",
    "    N = np.cross(X[T[:, 0], :] - X[T[:, 1], :], X[T[:, 0], :] - X[T[:, 2], :])\n",
    "    Ar = np.linalg.norm(N, axis=1)\n",
    "\n",
    "    # Use barycentric area when cot is negative\n",
    "    locs = np.where(cA[:, 0] < 0)[0]\n",
    "    At[locs, 0] = Ar[locs] / 4\n",
    "    At[locs, 1] = Ar[locs] / 8\n",
    "    At[locs, 2] = Ar[locs] / 8\n",
    "    locs = np.where(cA[:, 1] < 0)[0]\n",
    "    At[locs, 0] = Ar[locs] / 8\n",
    "    At[locs, 1] = Ar[locs] / 4\n",
    "    At[locs, 2] = Ar[locs] / 8\n",
    "    locs = np.where(cA[:, 2] < 0)[0]\n",
    "    At[locs, 0] = Ar[locs] / 8\n",
    "    At[locs, 1] = Ar[locs] / 8\n",
    "    At[locs, 2] = Ar[locs] / 4\n",
    "\n",
    "    # Vertex areas = sum triangles nearby\n",
    "    I = np.vstack((T[:, 0], T[:, 1], T[:, 2])).flatten()\n",
    "    J = np.ones(len(I))\n",
    "    S = 0.5*cot(np.vstack((At[:, 0], At[:, 1], At[:, 2])).flatten())\n",
    "\n",
    "\n",
    "    print(\"I\",I)\n",
    "    print(\"J\",J)\n",
    "    print(\"S\",S)\n",
    "    W = coo_matrix((Sn, (In, Jn)), shape=(nv, nv))\n",
    "    A = coo_matrix((S, (I, J)), shape=(nv, 1))\n",
    "\n",
    "\n",
    "    return W, A\n",
    "\n",
    "def normv(V):\n",
    "    return np.sqrt(np.sum(V**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_mesh_data(X, T, num_eigs=10, name='mesh'):\n",
    "    mesh = {}\n",
    "    mesh['vertices'] = X\n",
    "    mesh['triangles'] = T\n",
    "    mesh['name'] = name\n",
    "    \n",
    "    mesh['cotLaplacian'], mesh['areaWeights'] = cot_laplacian(X, T)\n",
    "\n",
    "    # Change to negative cot Laplacian and rescale to area = 1\n",
    "    mesh['areaWeights'] = mesh['areaWeights'] / np.sum(mesh['areaWeights'])\n",
    "    mesh['cotLaplacian'] = -1 * mesh['cotLaplacian']\n",
    "\n",
    "    mesh['numVertices'] = X.shape[0]\n",
    "    mesh['numTriangles'] = T.shape[0]\n",
    "\n",
    "    evec = np.vstack((T[:, 0], T[:, 1], T[:, 1], T[:, 2], T[:, 0], T[:, 2])).T\n",
    "    evec = np.unique(np.sort(evec, axis=1), axis=0)\n",
    "    ordered_rows = np.where(evec[:, 0] < evec[:, 1])[0]\n",
    "    mesh['edges'] = evec[ordered_rows, :]\n",
    "    mesh['numEdges'] = mesh['edges'].shape[0]\n",
    "\n",
    "    # Compute LB eigenstuff\n",
    "    area_matrix = csr_matrix((mesh['areaWeights'], (np.arange(1, mesh['numVertices'] + 1), np.arange(1, mesh['numVertices'] + 1))))\n",
    "    if num_eigs > 0:\n",
    "        evals, evecs = eigh(mesh['cotLaplacian'].todense(), area_matrix.todense(), eigvals=(0, num_eigs - 1), overwrite_a=True, overwrite_b=True)\n",
    "        mesh['laplaceBasis'] = evecs\n",
    "        mesh['eigenvalues'] = evals\n",
    "\n",
    "    normalf = np.cross(mesh['vertices'][mesh['triangles'][:, 1], :].T - mesh['vertices'][mesh['triangles'][:, 0], :].T,\n",
    "                       mesh['vertices'][mesh['triangles'][:, 2], :].T - mesh['vertices'][mesh['triangles'][:, 0], :].T)\n",
    "    d = np.sqrt(np.sum(normalf**2, axis=0))\n",
    "    d[d < np.finfo(float).eps] = 1\n",
    "    mesh['faceNormals'] = (normalf / d).T\n",
    "\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat kernel pour mesh\n",
    "\n",
    "\n",
    "def heat_kernel_on_mesh(signal, M, time, steps, transpose=False):\n",
    "    # equivalent de t pour time et steps pour m\n",
    "    h = time / steps\n",
    "    nv = M.numVertices\n",
    "\n",
    "    # We really should pre-factor this for speed...\n",
    "    blur_inverse = spdiags(M.areaWeights, 0, nv, nv) - h * M.cotLaplacian\n",
    "\n",
    "    result = signal.copy()\n",
    "\n",
    "    if not transpose:\n",
    "        for i in range(steps):\n",
    "            result = spsolve(blur_inverse, np.multiply(result, M.areaWeights))\n",
    "    else:\n",
    "        for i in range(steps):\n",
    "            result = np.multiply(spsolve(blur_inverse.transpose(), result), M.areaWeights)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I [array([   5,   21,   33, ..., 4332, 4282, 4334]), array([3108, 3085, 3197, ..., 4322, 4334, 4282]), array([3110, 3111,   34, ..., 4321, 4295, 4322])]\n",
      "J [1. 1. 1.]\n",
      "S [[1.57895614 0.31896955 0.55497207 ... 0.39536848 0.57965524 0.39036811]\n",
      " [1.57895614 0.60277205 0.55497207 ... 0.25946713 0.54219564 0.32249437]\n",
      " [0.71031185 0.33127019 0.05224948 ... 0.15021152 0.1161692  0.03779223]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "row, column, and data arrays must be 1-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Hippolyte/Desktop/P1/Geometric data analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb Cellule 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Main script\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Load shape\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m X, T \u001b[39m=\u001b[39m read_off(\u001b[39m'\u001b[39m\u001b[39m../data/wolf0.off\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m M \u001b[39m=\u001b[39m get_mesh_data(X, T, \u001b[39m10\u001b[39;49m)  \u001b[39m# Compute 10 LB eigenfunctions for fun\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Design two distributions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m blur_time \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m\n",
      "\u001b[1;32m/Users/Hippolyte/Desktop/P1/Geometric data analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb Cellule 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mesh[\u001b[39m'\u001b[39m\u001b[39mtriangles\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m T\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mesh[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m name\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m mesh[\u001b[39m'\u001b[39m\u001b[39mcotLaplacian\u001b[39m\u001b[39m'\u001b[39m], mesh[\u001b[39m'\u001b[39m\u001b[39mareaWeights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cot_laplacian(X, T)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Change to negative cot Laplacian and rescale to area = 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m mesh[\u001b[39m'\u001b[39m\u001b[39mareaWeights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m mesh[\u001b[39m'\u001b[39m\u001b[39mareaWeights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(mesh[\u001b[39m'\u001b[39m\u001b[39mareaWeights\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/Hippolyte/Desktop/P1/Geometric data analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb Cellule 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m,S)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m W \u001b[39m=\u001b[39m coo_matrix((Sn, (In, Jn)), shape\u001b[39m=\u001b[39m(nv, nv))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m A \u001b[39m=\u001b[39m coo_matrix((S, (I, J)), shape\u001b[39m=\u001b[39;49m(nv, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Hippolyte/Desktop/P1/Geometric%20data%20analysis/Convolutional-Wassertein-Distances/Codes/mesh_kernels.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m W, A\n",
      "File \u001b[0;32m~/anaconda3/envs/optimaltransport/lib/python3.11/site-packages/scipy/sparse/_coo.py:204\u001b[0m, in \u001b[0;36m_coo_base.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check()\n",
      "File \u001b[0;32m~/anaconda3/envs/optimaltransport/lib/python3.11/site-packages/scipy/sparse/_coo.py:289\u001b[0m, in \u001b[0;36m_coo_base._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m    287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m to_native(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m--> 289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnnz \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    291\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrow index exceeds matrix dimensions\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/optimaltransport/lib/python3.11/site-packages/scipy/sparse/_base.py:294\u001b[0m, in \u001b[0;36m_spbase.nnz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnnz\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Number of stored values, including explicit zeros.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[39m    See also\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    count_nonzero : Number of non-zero entries\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getnnz()\n",
      "File \u001b[0;32m~/anaconda3/envs/optimaltransport/lib/python3.11/site-packages/scipy/sparse/_coo.py:256\u001b[0m, in \u001b[0;36m_coo_base._getnnz\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrow, column, and data array must all be the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    252\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39msame length\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m    255\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrow, column, and data arrays must be 1-D\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(nnz)\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: row, column, and data arrays must be 1-D"
     ]
    }
   ],
   "source": [
    "# Pour entropy du barycentre sur le chat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Functions for mesh-related operations\n",
    "def read_off(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        num_vertices, num_faces, _ = map(int, lines[1].split())\n",
    "        vertices = np.array([list(map(float, line.split()[:3])) for line in lines[2:2 + num_vertices]])\n",
    "        faces = np.array([list(map(int, line.split()[1:])) for line in lines[2 + num_vertices:]])\n",
    "    return vertices, faces\n",
    "\n",
    "\n",
    "\n",
    "# Main script\n",
    "# Load shape\n",
    "X, T = read_off('../data/wolf0.off')\n",
    "M = get_mesh_data(X, T, 10)  # Compute 10 LB eigenfunctions for fun\n",
    "\n",
    "# Design two distributions\n",
    "blur_time = 0.0001\n",
    "blur_steps = 10\n",
    "\n",
    "front_vtx = [18962, 15966]\n",
    "back_vtx = [26142, 22553]\n",
    "\n",
    "p0 = np.zeros(M['numVertices'])\n",
    "for i in range(len(front_vtx)):\n",
    "    p0[front_vtx[i]] = 0.5 / M['areaWeights'][front_vtx[i]]\n",
    "p0 = heat_kernel_on_mesh(p0, M, blur_time, blur_steps)\n",
    "\n",
    "p1 = np.zeros(M['numVertices'])\n",
    "for i in range(len(back_vtx)):\n",
    "    p1[back_vtx[i]] = 0.5 / M['areaWeights'][back_vtx[i]]\n",
    "p1 = heat_kernel_on_mesh(p1, M, blur_time, blur_steps)\n",
    "\n",
    "# Set up Gaussian blur function for barycenter\n",
    "blur_time = 0.00015\n",
    "blur_steps = 10\n",
    "\n",
    "blur = lambda x: heat_kernel_on_mesh(x, M, blur_time, blur_steps)\n",
    "blur_transpose = blur\n",
    "\n",
    "# Take the barycenter\n",
    "p = np.column_stack((p0, p1))\n",
    "p[p < 1e-10] = 1e-10\n",
    "n_functions = 2\n",
    "\n",
    "max_entropy = -np.sum(p * np.log(p) * np.tile(M['areaWeights'], (1, 2)), axis=0).max()\n",
    "\n",
    "entropy_limits = [max_entropy, max_entropy + 1, max_entropy + 2, max_entropy + 3, np.inf]\n",
    "n_entropies = len(entropy_limits)\n",
    "\n",
    "euclidean_barycenter = np.sum(p, axis=1) / n_functions\n",
    "alpha = np.array([1, 1])\n",
    "\n",
    "options = {'niter': 100, 'unit_area_projection': 1}\n",
    "\n",
    "barycenter = Parallel(n_jobs=-1)(\n",
    "    delayed(convolutional_barycenter)(p, alpha, M['areaWeights'], blur, blur_transpose, entropy_limit, options)\n",
    "    for entropy_limit in entropy_limits\n",
    ")\n",
    "\n",
    "savemat('entropyTest.mat', {'barycenter': barycenter, 'M': M, 'p0': p0, 'p1': p1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimaltransport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
